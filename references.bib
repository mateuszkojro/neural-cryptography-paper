
@misc{borujeni_quantum_2021,
	title = {Quantum circuit representation of {Bayesian} networks},
	url = {http://arxiv.org/abs/2004.14803},
	abstract = {Probabilistic graphical models such as Bayesian networks are widely used to model stochastic systems to perform various types of analysis such as probabilistic prediction, risk analysis, and system health monitoring, which can become computationally expensive in large-scale systems. While demonstrations of true quantum supremacy remain rare, quantum computing applications managing to exploit the advantages of amplitude amplification have shown significant computational benefits when compared against their classical counterparts. We develop a systematic method for designing a quantum circuit to represent a generic discrete Bayesian network with nodes that may have two or more states, where nodes with more than two states are mapped to multiple qubits. The marginal probabilities associated with root nodes (nodes without any parent nodes) are represented using rotation gates, and the conditional probability tables associated with non-root nodes are represented using controlled rotation gates. The controlled rotation gates with more than one control qubit are represented using ancilla qubits. The proposed approach is demonstrated for three examples: a 4-node oil company stock prediction, a 10-node network for liquidity risk assessment, and a 9-node naive Bayes classifier for bankruptcy prediction. The circuits were designed and simulated using Qiskit, a quantum computing platform that enables simulations and also has the capability to run on real quantum hardware. The results were validated against those obtained from classical Bayesian network implementations.},
	urldate = {2022-06-29},
	collaborator = {Borujeni, Sima E. and Nannapaneni, Saideep and Nguyen, Nam H. and Behrman, Elizabeth C. and Steck, James E.},
	month = apr,
	year = {2021},
	note = {Number: arXiv:2004.14803
arXiv:2004.14803 [quant-ph]},
	keywords = {Computer Science - Computational Engineering, Finance, and Science, Quantum Physics},
}

@misc{fosel_quantum_2021,
	title = {Quantum circuit optimization with deep reinforcement learning},
	url = {http://arxiv.org/abs/2103.07585},
	abstract = {A central aspect for operating future quantum computers is quantum circuit optimization, i.e., the search for efficient realizations of quantum algorithms given the device capabilities. In recent years, powerful approaches have been developed which focus on optimizing the high-level circuit structure. However, these approaches do not consider and thus cannot optimize for the hardware details of the quantum architecture, which is especially important for near-term devices. To address this point, we present an approach to quantum circuit optimization based on reinforcement learning. We demonstrate how an agent, realized by a deep convolutional neural network, can autonomously learn generic strategies to optimize arbitrary circuits on a specific architecture, where the optimization target can be chosen freely by the user. We demonstrate the feasibility of this approach by training agents on 12-qubit random circuits, where we find on average a depth reduction by 27\% and a gate count reduction by 15\%. We examine the extrapolation to larger circuits than used for training, and envision how this approach can be utilized for near-term quantum devices.},
	urldate = {2022-06-29},
	collaborator = {Fösel, Thomas and Niu, Murphy Yuezhen and Marquardt, Florian and Li, Li},
	month = mar,
	year = {2021},
	note = {Number: arXiv:2103.07585
arXiv:2103.07585 [quant-ph]},
	keywords = {Quantum Physics},
}

@article{peres_quantum_2004,
	title = {Quantum {Information} and {Relativity} {Theory}},
	volume = {76},
	issn = {0034-6861, 1539-0756},
	url = {http://arxiv.org/abs/quant-ph/0212023},
	doi = {10.1103/RevModPhys.76.93},
	abstract = {Quantum mechanics, information theory, and relativity theory are the basic foundations of theoretical physics. The acquisition of information from a quantum system is the interface of classical and quantum physics. Essential tools for its description are Kraus matrices and positive operator valued measures (POVMs). Special relativity imposes severe restrictions on the transfer of information between distant systems. Quantum entropy is not a Lorentz covariant concept. Lorentz transformations of reduced density matrices for entangled systems may not be completely positive maps. Quantum field theory, which is necessary for a consistent description of interactions, implies a fundamental trade-off between detector reliability and localizability. General relativity produces new, counterintuitive effects, in particular when black holes (or more generally, event horizons) are involved. Most of the current concepts in quantum information theory may then require a reassessment.},
	number = {1},
	urldate = {2022-06-17},
	journal = {Reviews of Modern Physics},
	author = {Peres, Asher and Terno, Daniel R.},
	month = jan,
	year = {2004},
	note = {arXiv:quant-ph/0212023},
	keywords = {General Relativity and Quantum Cosmology, High Energy Physics - Theory, Quantum Physics},
	pages = {93--123},
}

@article{evans_lhc_2008,
	title = {{LHC} {Machine}},
	volume = {3},
	issn = {1748-0221},
	url = {https://doi.org/10.1088/1748-0221/3/08/s08001},
	doi = {10.1088/1748-0221/3/08/S08001},
	abstract = {The Large Hadron Collider (LHC) at CERN near Geneva is the world's newest and most powerful tool for Particle Physics research. It is designed to collide proton beams with a centre-of-mass energy of 14 TeV and an unprecedented luminosity of 1034 cm−2 s−1. It can also collide heavy (Pb) ions with an energy of 2.8 TeV per nucleon and a peak luminosity of 1027 cm−2 s−1. In this paper, the machine design is described.},
	language = {en},
	number = {08},
	urldate = {2022-06-17},
	journal = {Journal of Instrumentation},
	author = {Evans, Lyndon and Bryant, Philip},
	month = aug,
	year = {2008},
	note = {Publisher: IOP Publishing},
	pages = {S08001--S08001},
}

@article{noauthor_atlas_2016,
	title = {The {ATLAS} {Data} {Acquisition} and {High} {Level} {Trigger} system},
	volume = {11},
	issn = {1748-0221},
	url = {https://doi.org/10.1088/1748-0221/11/06/p06008},
	doi = {10.1088/1748-0221/11/06/P06008},
	abstract = {This paper describes the data acquisition and high level trigger system of the ATLAS experiment at the Large Hadron Collider at CERN, as deployed during Run 1. Data flow as well as control, configuration and monitoring aspects are addressed. An overview of the functionality of the system and of its performance is presented and design choices are discussed.},
	language = {en},
	number = {06},
	urldate = {2022-06-17},
	journal = {Journal of Instrumentation},
	month = jun,
	year = {2016},
	note = {Publisher: IOP Publishing},
	pages = {P06008--P06008},
}

@article{collaboration_atlas_2008,
	title = {The {ATLAS} {Experiment} at the {CERN} {Large} {Hadron} {Collider}},
	volume = {3},
	issn = {1748-0221},
	url = {https://iopscience.iop.org/article/10.1088/1748-0221/3/08/S08003},
	doi = {10.1088/1748-0221/3/08/S08003},
	abstract = {The ATLAS detector as installed in its experimental cavern at point 1 at CERN is described in this paper. A brief overview of the expected performance of the detector when the Large Hadron Collider begins operation is also presented.},
	number = {08},
	urldate = {2022-06-17},
	journal = {Journal of Instrumentation},
	author = {Collaboration, The ATLAS and Aad, G and Abat, E and Abdallah, J and Abdelalim, A A and Abdesselam, A and Abdinov, O and Abi, B A and Abolins, M and Abramowicz, H and Acerbi, E and Acharya, B S and Achenbach, R and Ackers, M and Adams, D L and Adamyan, F and Addy, T N and Aderholz, M and Adorisio, C and Adragna, P and Aharrouche, M and Ahlen, S P and Ahles, F and Ahmad, A and Ahmed, H and Aielli, G and Åkesson, P F and Åkesson, T P A and Akimov, A V and Alam, S M and Albert, J and Albrand, S and Aleksa, M and Aleksandrov, I N and Aleppo, M and Alessandria, F and Alexa, C and Alexander, G and Alexopoulos, T and Alimonti, G and Aliyev, M and Allport, P P and Allwood-Spiers, S E and Aloisio, A and Alonso, J and Alves, R and Alviggi, M G and Amako, K and Amaral, P and Amaral, S P and Ambrosini, G and Ambrosio, G and Amelung, C and Ammosov, V V and Amorim, A and Amram, N and Anastopoulos, C and Anderson, B and Anderson, K J and Anderssen, E C and Andreazza, A and Andrei, V and Andricek, L and Andrieux, M-L and Anduaga, X S and Anghinolfi, F and Antonaki, A and Antonelli, M and Antonelli, S and Apsimon, R and Arabidze, G and Aracena, I and Arai, Y and Arce, A T H and Archambault, J P and Arguin, J-F and Arik, E and Arik, M and Arms, K E and Armstrong, S R and Arnaud, M and Arnault, C and Artamonov, A and Asai, S and Ask, S and Åsman, B and Asner, D and Asquith, L and Assamagan, K and Astbury, A and Athar, B and Atkinson, T and Aubert, B and Auerbach, B and Auge, E and Augsten, K and Aulchenko, V M and Austin, N and Avolio, G and Avramidou, R and Axen, A and Ay, C and Azuelos, G and Baccaglioni, G and Bacci, C and Bachacou, H and Bachas, K and Bachy, G and Badescu, E and Bagnaia, P and Bailey, D C and Baines, J T and Baker, O K and Ballester, F and Pedrosa, F Baltasar Dos Santos and Banas, E and Banfi, D and Bangert, A and Bansal, V and Baranov, S P and Baranov, S and Barashkou, A and Barberio, E L and Barberis, D and Barbier, G and Barclay, P and Bardin, D Y and Bargassa, P and Barillari, T and Barisonzi, M and Barnett, B M and Barnett, R M and Baron, S and Baroncelli, A and Barone, M and Barr, A J and Barreiro, F and Costa, J Barreiro Guimarães da and Barrillon, P and Poy, A Barriuso and Barros, N and Bartheld, V and Bartko, H and Bartoldus, R and Basiladze, S and Bastos, J and Batchelor, L E and Bates, R L and Batley, J R and Batraneanu, S and Battistin, M and Battistoni, G and Batusov, V and Bauer, F and Bauss, B and Baynham, D E and Bazalova, M and Bazan, A and Beauchemin, P H and Beaugiraud, B and Beccherle, R B and Beck, G A and Beck, H P and Becks, K H and Bedajanek, I and Beddall, A J and Beddall, A and Bednár, P and Bednyakov, V A and Bee, C and Harpaz, S Behar and Belanger, G A N and Belanger-Champagne, C and Belhorma, B and Bell, P J and Bell, W H and Bella, G and Bellachia, F and Bellagamba, L and Bellina, F and Bellomo, G and Bellomo, M and Beltramello, O and Belymam, A and Ami, S Ben and Moshe, M Ben and Benary, O and Benchekroun, D and Benchouk, C and Bendel, M and Benedict, B H and Benekos, N and Benes, J and Benhammou, Y and Benincasa, G P and Benjamin, D P and Bensinger, J R and Benslama, K and Bentvelsen, S and Beretta, M and Berge, D and Bergeaas, E and Berger, N and Berghaus, F and Berglund, S and Bergsma, F and Beringer, J and Bernabéu, J and Bernardet, K and Berriaud, C and Berry, T and Bertelsen, H and Bertin, A and Bertinelli, F and Bertolucci, S and Besson, N and Beteille, A and Bethke, S and Bialas, W and Bianchi, R M and Bianco, M and Biebel, O and Bieri, M and Biglietti, M and Bilokon, H and Binder, M and Binet, S and Bingefors, N and Bingul, A and Bini, C and Biscarat, C and Bischof, R and Bischofberger, M and Bitadze, A and Bizzell, J P and Black, K M and Blair, R E and Blaising, J J and Blanch, O and Blanchot, G and Blocker, C and Blocki, J and Blondel, A and Blum, W and Blumenschein, U and Boaretto, C and Bobbink, G J and Bocci, A and Bocian, D and Bock, R and Boehm, M and Boek, J and Bogaerts, J A and Bogouch, A and Bohm, C and Bohm, J and Boisvert, V and Bold, T and Boldea, V and Bondarenko, V G and Bonino, R and Bonis, J and Bonivento, W and Bonneau, P and Boonekamp, M and Boorman, G and Boosten, M and Booth, C N and Booth, P S L and Booth, P and Booth, J R A and Borer, K and Borisov, A and Borjanovic, I and Bos, K and Boscherini, D and Bosi, F and Bosman, M and Bosteels, M and Botchev, B and Boterenbrood, H and Botterill, D and Boudreau, J and Bouhova-Thacker, E V and Boulahouache, C and Bourdarios, C and Boutemeur, M and Bouzakis, K and Boyd, G R and Boyd, J and Boyer, B H and Boyko, I R and Bozhko, N I and Braccini, S and Braem, A and Branchini, P and Brandenburg, G W and Brandt, A and Brandt, O and Bratzler, U and Braun, H M and Bravo, S and Brawn, I P and Brelier, B and Bremer, J and Brenner, R and Bressler, S and Breton, D and Brett, N D and Breugnon, P and Bright-Thomas, P G and Brochu, F M and Brock, I and Brock, R and Brodbeck, T J and Brodet, E and Broggi, F and Broklova, Z and Bromberg, C and Brooijmans, G and Brouwer, G and Broz, J and Brubaker, E and Renstrom, P A Bruckman de and Bruncko, D and Bruni, A and Bruni, G and Bruschi, M and Buanes, T and Buchanan, N J and Buchholz, P and Budagov, I A and Büscher, V and Bugge, L and Buira-Clark, D and Buis, E J and Bujor, F and Buran, T and Burckhart, H and Burckhart-Chromek, D and Burdin, S and Burns, R and Busato, E and Buskop, J J F and Buszello, K P and Butin, F and Butler, J M and Buttar, C M and Butterworth, J and Butterworth, J M and Byatt, T and Urbán, S Cabrera and Casas, E Cabruja and Caccia, M and Caforio, D and Cakir, O and Calafiura, P and Calderini, G and Terol, D Calderón and Callahan, J and Caloba, L P and Caloi, R and Calvet, D and Camard, A and Camarena, F and Camarri, P and Cambiaghi, M and Cameron, D and Cammin, J and Segura, F Campabadal and Campana, S and Canale, V and Cantero, J and Garrido, M D M Capeans and Caprini, I and Caprini, M and Caprio, M and Caracinha, D and Caramarcu, C and Carcagno, Y and Cardarelli, R and Cardeira, C and Sas, L Cardiel and Cardini, A and Carli, T and Carlino, G and Carminati, L and Caron, B and Caron, S and Carpentieri, C and Carr, F S and Carter, A A and Carter, J R and Carvalho, J and Casadei, D and Casado, M P and Cascella, M and Caso, C and Castelo, J and Gimenez, V Castillo and Castro, N and Castrovillari, F and Cataldi, G and Cataneo, F and Catinaccio, A and Catmore, J R and Cattai, A and Caughron, S and Cauz, D and Cavallari, A and Cavalleri, P and Cavalli, D and Cavalli-Sforza, M and Cavasinni, V and Ceradini, F and Cerna, C and Cernoch, C and Cerqueira, A S and Cerri, A and Cerutti, F and Cervetto, M and Cetin, S A and Cevenini, F and Chalifour, M and llatas, M Chamizo and Chan, A and Chapman, J W and Charlton, D G and Charron, S and Chekulaev, S V and Chelkov, G A and Chen, H and Chen, L and Chen, T and Chen, X and Cheng, S and Cheng, T L and Cheplakov, A and Chepurnov, V F and Moursli, R Cherkaoui El and Chesneanu, D and Cheu, E and Chevalier, L and Chevalley, J L and Chevallier, F and Chiarella, V and Chiefari, G and Chikovani, L and Chilingarov, A and Chiodini, G and Chouridou, S and Chren, D and Christiansen, T and Christidi, I A and Christov, A and Chu, M L and Chudoba, J and Chuguev, A G and Ciapetti, G and Cicalini, E and Ciftci, A K and Cindro, V and Ciobotaru, M D and Ciocio, A and Cirilli, M and Citterio, M and Ciubancan, M and Civera, J V and Clark, A and Cleland, W and Clemens, J C and Clement, B C and Clément, C and Clements, D and Clifft, R W and Cobal, M and Coccaro, A and Cochran, J and Coco, R and Coe, P and Coelli, S and Cogneras, E and Cojocaru, C D and Colas, J and Colijn, A P and Collard, C and Collins-Tooth, C and Collot, J and Coluccia, R and Comune, G and Muiño, P Conde and Coniavitis, E and Consonni, M and Constantinescu, S and Conta, C and Conventi, F A and Cook, J and Cooke, M and Cooper-Smith, N J and Cornelissen, T and Corradi, M and Correard, S and Corso-Radu, A and Coss, J and Costa, G and Costa, M J and Costanzo, D and Costin, T and Torres, R Coura and Courneyea, L and Couyoumtzelis, C and Cowan, G and Cox, B E and Cox, J and Cragg, D A and Cranmer, K and Cranshaw, J and Cristinziani, M and Crosetti, G and Almenar, C Cuenca and Cuneo, S and Cunha, A and Curatolo, M and Curtis, C J and Cwetanski, P and Czyczula, Z and D'Auria, S and D'Onofrio, M and Mello, A Da Rocha Gesualdi and Silva, P V M Da and Silva, R Da and Dabrowski, W and Dael, A and Dahlhoff, A and Dai, T and Dallapiccola, C and Dallison, S J and Dalmau, J and Daly, C H and Dam, M and Damazio, D and Dameri, M and Danielsen, K M and Danielsson, H O and Dankers, R and Dannheim, D and Darbo, G and Dargent, P and Daum, C and Dauvergne, J P and David, M and Davidek, T and Davidson, N and Davidson, R and Dawson, I and Dawson, J W and Daya, R K and De, K and Asmundis, R de and Boer, R de and Castro, S De and Groot, N De and Jong, P de and Broise, X de La and Cruz-Burelo, E De La and Taille, C De La and Lotto, B De and Branco, M De Oliveira and Pedis, D De and Saintignon, P de and Salvo, A De and Sanctis, U De and Santo, A De and Regie, J B De Vivie De and Zorzi, G De and Dean, S and Dedes, G and Dedovich, D V and Defay, P O and Degele, R and Dehchar, M and Deile, M and Papa, C Del and Peso, J Del and Prete, T Del and Delagnes, E and Delebecque, P and Dell'Acqua, A and Pietra, M Della and Volpe, D della and Delmastro, M and Delpierre, P and Delruelle, N and Delsart, P A and Silberberg, C Deluca and Demers, S and Demichev, M and Demierre, P and Demirköz, B and Deng, W and Denisov, S P and Dennis, C and Densham, C J and Dentan, M and Derkaoui, J E and Derue, F and Dervan, P and Desch, K K and Dewhurst, A and Ciaccio, A Di and Ciaccio, L Di and Domenico, A Di and Girolamo, A Di and Girolamo, B Di and Luise, S Di and Mattia, A Di and Simone, A Di and Gomez, M M Diaz and Diehl, E B and Dietl, H and Dietrich, J and Dietsche, W and Diglio, S and Dima, M and Dindar, K and Dinkespiler, B and Dionisi, C and Dipanjan, R and Dita, P and Dita, S and Dittus, F and Dixon, S D and Djama, F and Djilkibaev, R and Djobava, T and Vale, M A B do and Dobbs, M and Dobinson, R and Dobos, D and Dobson, E and Dobson, M and Dodd, J and Dogan, O B and Doherty, T and Doi, Y and Dolejsi, J and Dolenc, I and Dolezal, Z and Dolgoshein, B A and Domingo, E and Donega, M and Dopke, J and Dorfan, D E and Dorholt, O and Doria, A and Anjos, A Dos and Dosil, M and Dotti, A and Dova, M T and Dowell, J D and Doyle, A T and Drake, G and Drakoulakos, D and Drasal, Z and Drees, J and Dressnandt, N and Drevermann, H and Driouichi, C and Dris, M and Drohan, J G and Dubbert, J and Dubbs, T and Duchovni, E and Duckeck, G and Dudarev, A and Dührssen, M and Dür, H and Duerdoth, I P and Duffin, S and Duflot, L and Dufour, M-A and Dayot, N Dumont and Yildiz, H Duran and Durand, D and Dushkin, A and Duxfield, R and Dwuznik, M and Dydak, F and Dzahini, D and Cornell, S Díez and Düren, M and Ebenstein, W L and Eckert, S and Eckweiler, S and Eerola, P and Efthymiopoulos, I and Egede, U and Egorov, K and Ehrenfeld, W and Eifert, T and Eigen, G and Einsweiler, K and Eisenhandler, E and Ekelof, T and Eklund, L M and Kacimi, M El and Ellert, M and Elles, S and Ellis, N and Elmsheuser, J and Elsing, M and Ely, R and Emeliyanov, D and Engelmann, R and Engström, M and Ennes, P and Epp, B and Eppig, A and Epshteyn, V S and Ereditato, A and Eremin, V and Eriksson, D and Ermoline, I and Ernwein, J and Errede, D and Errede, S and Escalier, M and Escobar, C and Curull, X Espinal and Esposito, B and Esteves, F and Etienne, F and Etienvre, A I and Etzion, E and Evans, H and Evdokimov, V N and Evtoukhovitch, P and Eyring, A and Fabbri, L and Fabjan, C W and Fabre, C and Faccioli, P and Facius, K and Fadeyev, V and Fakhrutdinov, R M and Falciano, S and Falleau, I and Falou, A C and Fang, Y and Fanti, M and Farbin, A and Farilla, A and Farrell, J and Farthouat, P and Fasching, D and Fassi, F and Fassnacht, P and Fassouliotis, D and Fawzi, F and Fayard, L and Fayette, F and Febbraro, R and Fedin, O L and Fedorko, I and Feld, L and Feldman, G and Feligioni, L and Feng, C and Feng, E J and Fent, J and Fenyuk, A B and Ferencei, J and Ferguson, D and Ferland, J and Fernando, W and Ferrag, S and Ferrari, A and Ferrari, P and Ferrari, R and Ferrer, A and Ferrer, M L and Ferrere, D and Ferretti, C and Ferro, F and Fiascaris, M and Fichet, S and Fiedler, F and Filimonov, V and Filipčič, A and Filippas, A and Filthaut, F and Fincke-Keeler, M and Finocchiaro, G and Fiorini, L and Firan, A and Fischer, P and Fisher, M J and Fisher, S M and Flaminio, V and Flammer, J and Flechl, M and Fleck, I and Flegel, W and Fleischmann, P and Fleischmann, S and Corral, C M Fleta and Fleuret, F and Flick, T and Flix, J and Castillo, L R Flores and Flowerdew, M J and Föhlisch, F and Fokitis, M and Martin, T M Fonseca and Fopma, J and Forbush, D A and Formica, A and Foster, J M and Fournier, D and Foussat, A and Fowler, A J and Fox, H and Francavilla, P and Francis, D and Franz, S and Fraser, J T and Fraternali, M and Fratianni, S and Freestone, J and French, R S and Fritsch, K and Froidevaux, D and Frost, J A and Fukunaga, C and Fulachier, J and Torregrosa, E Fullana and Fuster, J and Gabaldon, C and Gadomski, S and Gagliardi, G and Gagnon, P and Gallas, E J and Gallas, M V and Gallop, B J and Gan, K K and Gannaway, F C and Gao, Y S and Gapienko, V A and Gaponenko, A and Garciá, C and Garcia-Sciveres, M and Navarro, J E Garcìa and Garde, V and Gardner, R W and Garelli, N and Garitaonandia, H and Garonne, V G and Garvey, J and Gatti, C and Gaudio, G and Gaumer, O and Gautard, V and Gauzzi, P and Gavrilenko, I L and Gay, C and Gayde, J-C and Gazis, E N and Gazo, E and Gee, C N P and Geich-Gimbel, C and Gellerstedt, K and Gemme, C and Genest, M H and Gentile, S and George, M A and George, S and Gerlach, P and Gernizky, Y and Geweniger, C and Ghazlane, H and Ghete, V M and Ghez, P and Ghodbane, N and Giacobbe, B and Giagu, S and Giakoumopoulou, V and Giangiobbe, V and Gianotti, F and Gibbard, B and Gibson, A and Gibson, M D and Gibson, S M and Gieraltowski, G F and Botella, I Gil and Gilbert, L M and Gilchriese, M and Gildemeister, O and Gilewsky, V and Gillman, A R and Gingrich, D M and Ginzburg, J and Giokaris, N and Giordani, M P and Girard, C G and Giraud, P F and Girtler, P and Giugni, D and Giusti, P and Gjelsten, B K and Glasman, C and Glazov, A and Glitza, K W and Glonti, G L and Gnanvo, K G and Godlewski, J and Göpfert, T and Gössling, C and Göttfert, T and Goldfarb, S and Goldin, D and Goldschmidt, N and Golling, T and Gollub, N P and Golonka, P J and Golovnia, S N and Gomes, A and Gomes, J and Gonçalo, R and Gongadze, A and Gonidec, A and Gonzalez, S and Hoz, S González de la and Millán, V González and Silva, M L Gonzalez and Gonzalez-Pineiro, B and González-Sevilla, S and Goodrick, M J and Goodson, J J and Goossens, L and Gorbounov, P A and Gordeev, A and Gordon, H and Gorelov, I and Gorfine, G and Gorini, B and Gorini, E and Gorišek, A and Gornicki, E and Gorokhov, S A and Gorski, B T and Goryachev, S V and Goryachev, V N and Gosselink, M and Gostkin, M I and Gouanère, M and Eschrich, I Gough and Goujdami, D and Goulette, M and Gousakov, I and Gouveia, J and Gowdy, S and Goy, C and Grabowska-Bold, I and Grabski, V and Grafström, P and Grah, C and Grahn, K-J and Grancagnolo, F and Grancagnolo, S and Grassmann, H and Gratchev, V and Gray, H M and Graziani, E and Green, B and Greenall, A and Greenfield, D and Greenwood, D and Gregor, I M and Grewal, A and Griesmayer, E and Grigalashvili, N and Grigson, C and Grillo, A A and Grimaldi, F and Grimm, K and Gris, P L Y and Grishkevich, Y and Groenstege, H and Groer, L S and Grognuz, J and Groh, M and Gross, E and Grosse-Knetter, J and Grothe, M E M and Grudzinski, J and Gruse, C and Gruwe, M and Grybel, K and Grybos, P and Gschwendtner, E M and Guarino, V J and Guicheney, C J and Guilhem, G and Guillemin, T and Gunther, J and Guo, B and Gupta, A and Gurriana, L and Gushchin, V N and Gutierrez, P and Guy, L and Guyot, C and Gwenlan, C and Gwilliam, C B and Haas, A and Haas, S and Haber, C and Haboubi, G and Hackenburg, R and Hadash, E and Hadavand, H K and Haeberli, C and Härtel, R and Haggerty, R and Hahn, F and Haider, S and Hajduk, Z and Hakimi, M and Hakobyan, H and Hakobyan, H and Haller, J and Hallewell, G D and Hallgren, B and Hamacher, K and Hamilton, A and Han, H and Han, L and Hanagaki, K and Hance, M and Hanke, P and Hansen, C J and Hansen, F H and Hansen, J R and Hansen, J B and Hansen, J D and Hansen, P H and Hansl-Kozanecka, T and Hanson, G and Hansson, P and Hara, K and Harder, S and Harel, A and Harenberg, T and Harper, R and Hart, J C and Hart, R G G and Hartjes, F and Hartman, N and Haruyama, T and Harvey, A and Hasegawa, Y and Hashemi, K and Hassani, S and Hatch, M and Hatley, R W and Haubold, T G and Hauff, D and Haug, F and Haug, S and Hauschild, M and Hauser, R and Hauviller, C and Havranek, M and Hawes, B M and Hawkings, R J and Hawkins, D and Hayler, T and Hayward, H S and Haywood, S J and Hazen, E and He, M and He, Y P and Head, S J and Hedberg, V and Heelan, L and Heinemann, F E W and Heldmann, M and Hellman, S and Helsens, C and Henderson, R C W and Hendriks, P J and Correia, A M Henriques and Henrot-Versille, S and Henry-Couannier, F and Henß, T and Herten, G and Hertenberger, R and Hervas, L and Hess, M and Hessey, N P and Hicheur, A and Hidvegi, A and Higón-Rodriguez, E and Hill, D and Hill, J and Hill, J C and Hill, N and Hillier, S J and Hinchliffe, I and Hindson, D and Hinkelbein, C and Hodges, T A and Hodgkinson, M C and Hodgson, P and Hoecker, A and Hoeferkamp, M R and Hoffman, J and Hoffmann, A E and Hoffmann, D and Hoffmann, H F and Holder, M and Hollins, T I and Hollyman, G and Holmes, A and Holmgren, S O and Holt, R and Holtom, E and Holy, T and Homer, R J and Homma, Y and Homola, P and Honerbach, W and Honma, A and Hooton, I and Horazdovsky, T and Horn, C and Horvat, S and Hostachy, J-Y and Hott, T and Hou, S and Houlden, M A and Hoummada, A and Hover, J and Howell, D F and Hrivnac, J and Hruska, I and Hryn'ova, T and Huang, G S and Hubacek, Z and Hubaut, F and Huegging, F and Huffman, B T and Hughes, E and Hughes, G and Hughes-Jones, R E and Hulsbergen, W and Hurst, P and Hurwitz, M and Huse, T and Huseynov, N and Huston, J and Huth, J and Iacobucci, G and Ibbotson, M and Ibragimov, I and Ichimiya, R and Iconomidou-Fayard, L and Idarraga, J and Idzik, M and Iengo, P and Escudero, M C Iglesias and Igonkina, O and Ikegami, Y and Ikeno, M and Ilchenko, Y and Ilyushenka, Y and Imbault, D and Imbert, P and Imhaeuser, M and Imori, M and Ince, T and Inigo-Golfin, J and Inoue, K and Ioannou, P and Iodice, M and Ionescu, G and Ishii, K and Ishino, M and Ishizawa, Y and Ishmukhametov, R and Issever, C and Ito, H and Ivashin, A V and Iwanski, W and Iwasaki, H and Izen, J M and Izzo, V and Jackson, J and Jackson, J N and Jaekel, M and Jagielski, S and Jahoda, M and Jain, V and Jakobs, K and Jakubek, J and Jansen, E and Jansweijer, P P M and Jared, R C and Jarlskog, G and Jarp, S and Jarron, P and Jelen, K and Plante, I Jen-La and Jenni, P and Jeremie, A and Jez, P and Jézéquel, S and Jiang, Y and Jin, G and Jin, S and Jinnouchi, O and Joffe, D and Johansen, L G and Johansen, M and Johansson, K E and Johansson, P and Johns, K A and Jon-And, K and Jones, M and Jones, R and Jones, R W L and Jones, T W and Jones, T J and Jones, A and Jonsson, O and Joo, K K and Joos, D and Joos, M and Joram, C and Jorgensen, S and Joseph, J and Jovanovic, P and Junnarkar, S S and Juranek, V and Jussel, P and Kabachenko, V V and Kabana, S and Kaci, M and Kaczmarska, A and Kado, M and Kagan, H and Kagawa, S and Kaiser, S and Kajomovitz, E and Kakurin, S and Kalinovskaya, L V and Kama, S and Kambara, H and Kanaya, N and Kandasamy, A and Kandasamy, S and Kaneda, M and Kantserov, V A and Kanzaki, J and Kaplan, B and Kapliy, A and Kaplon, J and Karagounis, M and Unel, M Karagoz and Karr, K and Karst, P and Kartvelishvili, V and Karyukhin, A N and Kashif, L and Kasmi, A and Kass, R D and Kastanas, A and Kataoka, M and Kataoka, Y and Katsoufis, E and Katunin, S and Kawagoe, K and Kawai, M and Kawamoto, T and Kayumov, F and Kazanin, V A and Kazarinov, M Y and Kazarov, A and Kazi, S I and Keates, J R and Keeler, R and Keener, P T and Kehoe, R and Keil, M and Kekelidze, G D and Kelly, M and Kennedy, J and Kenyon, M and Kepka, O and Kerschen, N and Kerševan, B P and Kersten, S and Ketterer, C and Khakzad, M and Khalilzade, F and Khandanyan, H and Khanov, A and Kharchenko, D and Khodinov, A and Kholodenko, A G and Khomich, A and Khomutnikov, V P and Khoriauli, G and Khovanskiy, N and Khovanskiy, V and Khramov, E and Khubua, J and Kieft, G and Kierstead, J A and Kilvington, G and Kim, H and Kim, H and Kim, S H and Kind, P and King, B T and Kirk, J and Kirsch, G P and Kirsch, L E and Kiryunin, A E and Kisielewska, D and Kisielewski, B and Kittelmann, T and Kiver, A M and Kiyamura, H and Kladiva, E and Klaiber-Lodewigs, J and Kleinknecht, K and Klier, A and Klimentov, A and Kline, C R and Klingenberg, R and Klinkby, E B and Klioutchnikova, T and Klok, P F and Klous, S and Kluge, E-E and Kluit, P and Klute, M and Kluth, S and Knecht, N K and Kneringer, E and Knezo, E and Knobloch, J and Ko, B R and Kobayashi, T and Kobel, M and Kodys, P and König, A C and König, S and Köpke, L and Koetsveld, F and Koffas, T and Koffeman, E and Kohout, Z and Kohriki, T and Kokott, T and Kolachev, G M and Kolanoski, H and Kolesnikov, V and Koletsou, I and Kollefrath, M and Kolos, S and Kolya, S D and Komar, A A and Komaragiri, J R and Kondo, T and Kondo, Y and Kondratyeva, N V and Kono, T and Kononov, A I and Konoplich, R and Konovalov, S P and Konstantinidis, N and Kootz, A and Koperny, S and Kopikov, S V and Korcyl, K and Kordas, K and Koreshev, V and Korn, A and Korolkov, I and Korotkov, V A and Korsmo, H and Kortner, O and Kostrikov, M E and Kostyukhin, V V and Kotamäki, M J and Kotchetkov, D and Kotov, S and Kotov, V M and Kotov, K Y and Kourkoumelis, C and Koutsman, A and Kovalenko, S and Kowalewski, R and Kowalski, H and Kowalski, T Z and Kozanecki, W and Kozhin, A S and Kral, V and Kramarenko, V and Kramberger, G and Kramer, A and Krasel, O and Krasny, M W and Krasznahorkay, A and Krepouri, A and Krieger, P and Krivkova, P and Krobath, G and Kroha, H and Krstic, J and Kruchonak, U and Krüger, H and Kruger, K and Krumshteyn, Z V and Kubik, P and Kubischta, W and Kubota, T and Kudin, L G and Kudlaty, J and Kugel, A and Kuhl, T and Kuhn, D and Kukhtin, V and Kulchitsky, Y and Kundu, N and Kupco, A and Kupper, M and Kurashige, H and Kurchaninov, L L and Kurochkin, Y A and Kus, V and Kuykendall, W and Kuzhir, P and Kuznetsova, E K and Kvasnicka, O and Kwee, R and Marra, D La and Rosa, M La and Rotonda, L La and Labarga, L and Labbe, J A and Lacasta, C and Lacava, F and Lacker, H and Lacour, D and Lacuesta, V R and Ladygin, E and Lafaye, R and Laforge, B and Lagouri, T and Lai, S and Lamanna, E and Lambacher, M and Lambert, F and Lampl, W and Lancon, E and Landgraf, U and Landon, M P J and Landsman, H and Langstaff, R R and Lankford, A J and Lanni, F and Lantzsch, K and Lanza, A and Lapin, V V and Laplace, S and Laporte, J F and Lara, V and Lari, T and Larionov, A V and Lasseur, C and Lau, W and Laurelli, P and Lavorato, A and Lavrijsen, W and Lazarev, A B and Bihan, A-C Le and Dortz, O Le and Maner, C Le and Vine, M Le and Leahu, L and Leahu, M and Lebel, C and Lechowski, M and LeCompte, T and Ledroit-Guillon, F and Lee, H and Lee, J S H and Lee, S C and Lefebvre, M and Lefevre, R P and Legendre, M and Leger, A and LeGeyt, B C and Leggett, C and Lehmacher, M and Miotto, G Lehmann and Lehto, M and Leitner, R and Lelas, D and Lellouch, D and Leltchouk, M and Lendermann, V and Leney, K J C and Lenz, T and Lenzen, G and Lepidis, J and Leroy, C and Lessard, J-R and Lesser, J and Lester, C G and Letheren, M and Cheong, A Leung Fook and Levêque, J and Levin, D and Levinson, L J and Levitski, M S and Lewandowska, M and Leyton, M and Li, J and Li, W and Liabline, M and Liang, Z and Liang, Z and Liberti, B and Lichard, P and Liebig, W and Lifshitz, R and Liko, D and Lim, H and Limper, M and Lin, S C and Lindahl, A and Linde, F and Lindquist, L and Lindsay, S W and Linhart, V and Lintern, A J and Liolios, A and Lipniacka, A and Liss, T M and Lissauer, A and List, J and Litke, A M and Liu, S and Liu, T and Liu, Y and Livan, M and Lleres, A and Llácer, G Llosá and Lloyd, S L and Lobkowicz, F and Loch, P and Lockman, W S and Loddenkoetter, T and Loebinger, F K and Loginov, A and Loh, C W and Lohse, T and Lohwasser, K and Lokajicek, M and Loken, J and Lokwitz, S and Long, M C and Lopes, L and Mateos, D Lopez and Losty, M J and Lou, X and Loureiro, K F and Lovas, L and Love, J and Lowe, A and Fantoba, M Lozano and Lu, F and Lu, J and Lu, L and Lubatti, H J and Lucas, S and Luci, C and Lucotte, A and Ludwig, A and Ludwig, I and Ludwig, J and Luehring, F and Lüke, D and Luijckx, G and Luisa, L and Lumb, D and Luminari, L and Lund, E and Lund-Jensen, B and Lundberg, B and Lundquist, J and Lupi, A and Lupu, N and Lutz, G and Lynn, D and Lynn, J and Lys, J and Lysan, V and Lytken, E and López-Amengual, J M and Ma, H and Ma, L L and en, M Maaß and Maccarrone, G and Mace, G G R and Macina, D and Mackeprang, R and Macpherson, A and MacQueen, D and Macwaters, C and Madaras, R J and Mader, W F and Maenner, R and Maeno, T and Mättig, P and Mättig, S and Magrath, C A and Mahalalel, Y and Mahboubi, K and Mahout, G and Maidantchik, C and Maio, A and Mair, G M and Mair, K and Makida, Y and Makowiecki, D and Malecki, P and Maleev, V P and Malek, F and Malon, D and Maltezos, S and Malychev, V and Malyukov, S and Mambelli, M and Mameghani, R and Mamuzic, J and Manabe, A and Manara, A and Manca, G and Mandelli, L and Mandić, I and Mandl, M and Maneira, J and Maneira, M and Mangeard, P S and Mangin-Brinet, M and Manjavidze, I D and Mann, W A and Manolopoulos, S and Manousakis-Katsikakis, A and Mansoulie, B and Manz, A and Mapelli, A and Mapelli, L and March, L and Marchand, J F and Marchesotti, M and Marcisovsky, M and Marin, A and Marques, C N and Marroquim, F and Marshall, R and Marshall, Z and Martens, F K and Garcia, S Marti i and Martin, A J and Martin, B and Martin, B and Martin, F F and Martin, J P and Martin, Ph and Martinez, G and Lacambra, C Martínez and Outschoorn, V Martinez and Martini, A and Martins, J and Maruyama, T and Marzano, F and Mashimo, T and Mashinistov, R and Masik, J and Maslennikov, A L and Maß, M and Massa, I and Massaro, G and Massol, N and Mathes, M and Matheson, J and Matricon, P and Matsumoto, H and Matsunaga, H and Maugain, J M and Maxfield, S J and May, E N and Mayer, J K and Mayri, C and Mazini, R and Mazzanti, M and Mazzanti, P and Mazzoni, E and Mazzucato, F and Kee, S P Mc and McCarthy, R L and McCormick, C and McCubbin, N A and McDonald, J and McFarlane, K W and McGarvie, S and McGlone, H and McLaren, R A and McMahon, S J and McMahon, T R and McMahon, T J and McPherson, R A and Mechtel, M and Meder-Marouelli, D and Medinnis, M and Meera-Lebbai, R and Meessen, C and Mehdiyev, R and Mehta, A and Meier, K and Meinhard, H and Meinhardt, J and Meirosu, C and Meisel, F and Melamed-Katz, A and Garcia, B R Mellado and Jorge, P Mendes and Mendez, P and Menke, S and Menot, C and Meoni, E and Merkl, D and Merola, L and Meroni, C and Merritt, F S and Messmer, I and Metcalfe, J and Meuser, S and Meyer, J-P and Meyer, T C and Meyer, W T and Mialkovski, V and Michelotto, M and Micu, L and Middleton, R and Miele, P and Migliaccio, A and Mijović, L and Mikenberg, G and Mikestikova, M and Mikestikova, M and Mikulec, B and Mikuž, M and Miller, D W and Miller, R J and Miller, W and Milosavljevic, M and Milstead, D A and Mima, S and Minaenko, A A and Minano, M and Minashvili, I A and Mincer, A I and Mindur, B and Mineev, M and Mir, L M and Mirabelli, G and Verge, L Miralles and Misawa, S and Miscetti, S and Misiejuk, A and Mitra, A and Mitrofanov, G Y and Mitsou, V A and Miyagawa, P S and Miyazaki, Y and Mjörnmark, J U and Mkrtchyan, S and Mladenov, D and Moa, T and Moch, M and Mochizuki, A and Mockett, P and Modesto, P and Moed, S and Mönig, K and Möser, N and Mohn, B and Mohr, W and Mohrdieck-Möck, S and Moisseev, A M and Valls, R M Moles and Molina-Perez, J and Moll, A and Moloney, G and Mommsen, R and Moneta, L and Monnier, E and Montarou, G and Montesano, S and Monticelli, F and Moore, R W and Moore, T B and Moorhead, G F and Moraes, A and Morel, J and Moreno, A and Moreno, D and Morettini, P and Morgan, D and Morii, M and Morin, J and Morley, A K and Mornacchi, G and Morone, M-C and Morozov, S V and Morris, E J and Morris, J and Morrissey, M C and Moser, H G and Mosidze, M and Moszczynski, A and Mouraviev, S V and Mouthuy, T and Moye, T H and Moyse, E J W and Mueller, J and Müller, M and Muijs, A and Muller, T R and Munar, A and Munday, D J and Murakami, K and Garcia, R Murillo and Murray, W J and Myagkov, A G and Myska, M and Nagai, K and Nagai, Y and Nagano, K and Nagasaka, Y and Nairz, A M and Naito, D and Nakamura, K and Nakamura, Y and Nakano, I and Nanava, G and Napier, A and Nassiakou, M and Nasteva, I and Nation, N R and Naumann, T and Nauyock, F and Nderitu, S K and Neal, H A and Nebot, E and Nechaeva, P and Neganov, A and Negri, A and Negroni, S and Nelson, C and Nemecek, S and Nemethy, P and Nepomuceno, A A and Nessi, M and Nesterov, S Y and Neukermans, L and Nevski, P and Newcomer, F M and Nichols, A and Nicholson, C and Nicholson, R and Nickerson, R B and Nicolaidou, R and Nicoletti, G and Nicquevert, B and Niculescu, M and Nielsen, J and Niinikoski, T and Niinimaki, M J and Nikitin, N and Nikolaev, K and Nikolic-Audit, I and Nikolopoulos, K and Nilsen, H and Nilsson, B S and Nilsson, P and Nisati, A and Nisius, R and Nodulman, L J and Nomachi, M and Nomoto, H and Noppe, J-M and Nordberg, M and Francisco, O Norniella and Norton, P R and Novakova, J and Nowak, M and Nozaki, M and Nunes, R and Hanninger, G Nunes and Nunnemann, T and Nyman, T and O'Connor, P and O'Neale, S W and O'Neil, D C and O'Neill, M and O'Shea, V and Oakham, F G and Oberlack, H and Obermaier, M and Oberson, P and Ochi, A and Ockenfels, W and Odaka, S and Odenthal, I and Odino, G A and Ogren, H and Oh, S H and Ohshima, T and Ohshita, H and Okawa, H and Olcese, M and Olchevski, A G and Oliver, C and Oliver, J and Gomez, M Olivo and Olszewski, A and Olszowska, J and Omachi, C and Onea, A and Onofre, A and Oram, C J and Ordonez, G and Oreglia, M J and Orellana, F and Oren, Y and Orestano, D and Orlov, I O and Orr, R S and Orsini, F and Osborne, L S and Osculati, B and Osuna, C and Otec, R and Othegraven, R and Ottewell, B and Ould-Saada, F and Ouraou, A and Ouyang, Q and Øye, O K and Ozcan, V E and Ozone, K and Ozturk, N and Pages, A Pacheco and Padhi, S and Aranda, C Padilla and Paganis, E and Paige, F and Pailler, P M and Pajchel, K and Palestini, S and Palla, J and Pallin, D and Palmer, M J and Pan, Y B and Panikashvili, N and Panin, V N and Panitkin, S and Pantea, D and Panuskova, M and Paolone, V and Paoloni, A and Papadopoulos, I and Papadopoulou, T and Park, I and Park, W and Parker, M A and Parker, S and Parkman, C and Parodi, F and Parsons, J A and Parzefall, U and Pasqualucci, E and Passardi, G and Passeri, A and Passmore, M S and Pastore, F and Pastore, Fr and Pataraia, S and Pate, D and Pater, J R and Patricelli, S and Pauly, T and Pauna, E and Peak, L S and Peeters, S J M and Peez, M and Pei, E and Peleganchuk, S V and Pellegrini, G and Pengo, R and Pequenao, J and Perantoni, M and Perazzo, A and Pereira, A and Perepelkin, E and Perera, V J O and Codina, E Perez and Reale, V Perez and Peric, I and Perini, L and Pernegger, H and Perrin, E and Perrino, R and Perrodo, P and Perrot, G and Perus, P and Peshekhonov, V D and Petereit, E and Petersen, J and Petersen, T C and Petit, P J F and Petridou, C and Petrolo, E and Petrucci, F and Petti, R and Pezzetti, M and Pfeifer, B and Phan, A and Phillips, A W and Phillips, P W},
	month = aug,
	year = {2008},
	pages = {S08003--S08003},
}

@techreport{noauthor_technical_2017,
	address = {Geneva},
	title = {Technical {Design} {Report} for the {Phase}-{II} {Upgrade} of the {ATLAS} {TDAQ} {System}},
	url = {https://cds.cern.ch/record/2285584},
	institution = {CERN},
	month = sep,
	year = {2017},
	doi = {10.17181/CERN.2LBB.4IAL},
}

@techreport{noauthor_notitle_nodate,
}

@article{bernius_atlas_nodate,
	title = {The {ATLAS} {Trigger} \& {Data} {AcQuisition} ({TDAQ}) {System}},
	language = {en},
	author = {Bernius, Catrin},
	pages = {41},
}

@misc{noauthor_paxos_2022,
	title = {Paxos (computer science)},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Paxos_(computer_science)&oldid=1092251307},
	abstract = {Paxos is a family of protocols for solving consensus in a network of unreliable or fallible processors.
Consensus is the process of agreeing on one result among a group of participants.  This problem becomes difficult when the participants or their communications may experience failures.Consensus protocols are the basis for the state machine replication approach to distributed computing, as suggested by Leslie Lamport and surveyed by Fred Schneider.  State machine replication is a technique for converting an algorithm into a fault-tolerant, distributed implementation.  Ad-hoc techniques may leave important cases of failures unresolved.  The principled approach proposed by Lamport et al. ensures all cases are handled safely.
The Paxos protocol was first submitted in 1989 and named after a fictional legislative consensus system used on the Paxos island in Greece, where Lamport wrote that the parliament had to function "even though legislators continually wandered in and out of the parliamentary Chamber". It was later published as a journal article in 1998.The Paxos family of protocols includes a spectrum of trade-offs between the number of processors, number of message delays before learning the agreed value, the activity level of individual participants, number of messages sent, and types of failures.  Although no deterministic fault-tolerant consensus protocol can guarantee progress in an asynchronous network (a result proved in a paper by Fischer, Lynch and Paterson), Paxos guarantees safety (consistency), and the conditions that could prevent it from making progress are difficult to provoke.
Paxos is usually used where durability is required (for example, to replicate a file or a database), in which the amount of durable state could be large. The protocol attempts to make progress even during periods when some bounded number of replicas are unresponsive. There is also a mechanism to drop a permanently failed replica or to add a new replica.},
	urldate = {2022-06-14},
	journal = {Wikipedia},
	month = jun,
	year = {2022},
	note = {Page Version ID: 1092251307},
}

@inproceedings{gleinig_efficient_2021,
	address = {San Francisco, CA, USA},
	title = {An {Efficient} {Algorithm} for {Sparse} {Quantum} {State} {Preparation}},
	isbn = {978-1-66543-274-0},
	url = {https://ieeexplore.ieee.org/document/9586240/},
	doi = {10.1109/DAC18074.2021.9586240},
	abstract = {Generating quantum circuits that prepare speciﬁc states is an essential part of quantum compilation. Algorithms that solve this problem for general states generate circuits that grow exponentially in the number of qubits. However, in contrast to general states, many practically relevant states are sparse in the standard basis. In this paper we show how sparsity can be used for efﬁcient state preparation. We present a polynomial-time algorithm that generates polynomial-size quantum circuits (linear in the number of nonzero coefﬁcients times number of qubits) that prepare given states, making computer-aided design of sparse state preparation scalable.},
	language = {en},
	urldate = {2022-06-13},
	booktitle = {2021 58th {ACM}/{IEEE} {Design} {Automation} {Conference} ({DAC})},
	publisher = {IEEE},
	author = {Gleinig, Niels and Hoefler, Torsten},
	month = dec,
	year = {2021},
	pages = {433--438},
}

@techreport{araujo_approximated_2022,
	title = {Approximated quantum-state preparation with entanglement dependent complexity},
	url = {http://arxiv.org/abs/2111.03132},
	abstract = {Ubiquitous in quantum computing is the step to encode data into a quantum state. This process is called quantum state preparation, and its complexity for non-structured data is exponential on the number of qubits. Several works address this problem, for instance, by using variational methods that train a fixed depth circuit with manageable complexity. These methods have their limitations as the lack of a back-propagation technique and barren plateaus. This work proposes an algorithm to reduce state preparation circuit depth by offloading computational complexity to a classical computer. The initialized quantum state can be exact or an approximation, and we show that the approximation is better on today's quantum processors than the initialization of the original state. We verified through experimental evaluation that the proposed method allows the initialization of distributions in a quantum state and approximate loading images for quantum machine learning tasks. Indeed, our experiments on IBMQ devices show that they are likely to be aiding experimenters of quantum computing throughout the NISQ era.},
	number = {arXiv:2111.03132},
	urldate = {2022-06-13},
	institution = {arXiv},
	author = {Araujo, Israel F. and Blank, Carsten and da Silva, Adenilton J.},
	month = may,
	year = {2022},
	doi = {10.48550/arXiv.2111.03132},
	note = {arXiv:2111.03132 [quant-ph]
type: article},
	keywords = {Computer Science - Emerging Technologies, Quantum Physics},
}

@misc{daos_developers_daos_nodate,
	title = {{DAOS} and {Intel}® {Optane}™ {Technology} for {High}-{Performance} {Storage}},
	url = {https://www.intel.com/content/www/us/en/high-performance-computing/daos-high-performance-storage-brief.html},
	abstract = {Learn how DAOS, our open-source software stack, and Intel® Optane™ technology are revolutionizing high-performance storage.},
	language = {en},
	urldate = {2022-06-10},
	journal = {Intel},
	author = {DAOS Developers},
}

@misc{daos_developers_welcome_nodate,
	title = {Welcome to {DAOS} {Version} 2.0! - {DAOS} v2.0 - latest},
	url = {https://docs.daos.io/v2.0/},
	urldate = {2022-06-10},
	author = {DAOS Developers},
}

@article{montanaro_quantum_2016,
	title = {Quantum algorithms: an overview {\textbar} npj {Quantum} {Information}},
	volume = {2},
	issn = {2056-6387},
	shorttitle = {Quantum algorithms},
	url = {https://www.nature.com/articles/npjqi201523},
	doi = {10.1038/npjqi.2015.23},
	abstract = {Quantum computers are designed to outperform standard computers by running quantum algorithms. Areas in which quantum algorithms can be applied include cryptography, search and optimisation, simulation of quantum systems and solving large systems of linear equations. Here we briefly survey some known quantum algorithms, with an emphasis on a broad overview of their applications rather than their technical details. We include a discussion of recent developments and near-term applications of quantum algorithms.},
	number = {1},
	urldate = {2022-06-08},
	journal = {npj Quantum Information},
	author = {Montanaro, Ashley},
	month = jan,
	year = {2016},
	pages = {15023},
}

@misc{noauthor_protocols5_nodate,
	title = {protocols(5) - {Linux} manual page},
	url = {https://man7.org/linux/man-pages/man5/protocols.5.html},
	urldate = {2022-05-30},
}

@misc{noauthor_listen2_nodate,
	title = {listen(2) - {Linux} manual page},
	url = {https://man7.org/linux/man-pages/man2/listen.2.html},
	urldate = {2022-05-30},
}

@misc{noauthor_accept2_nodate,
	title = {accept(2) - {Linux} manual page},
	url = {https://man7.org/linux/man-pages/man2/accept.2.html},
	urldate = {2022-05-30},
}

@misc{noauthor_socket2_nodate,
	title = {socket(2) - {Linux} manual page},
	url = {https://man7.org/linux/man-pages/man2/socket.2.html},
	urldate = {2022-05-30},
}

@misc{noauthor_bind2_nodate,
	title = {bind(2) - {Linux} manual page},
	url = {https://man7.org/linux/man-pages/man2/bind.2.html},
	urldate = {2022-05-30},
}

@misc{noauthor_hypertext_2021,
	title = {Hypertext {Transfer} {Protocol}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://pl.wikipedia.org/w/index.php?title=Hypertext_Transfer_Protocol&oldid=65497426},
	abstract = {HTTP (ang. Hypertext Transfer Protocol) – protokół przesyłania dokumentów hipertekstowych to protokół sieci WWW (ang. World Wide Web). Obecną definicję HTTP stanowi RFC 2616 ↓. Za pomocą protokołu HTTP przesyła się żądania udostępnienia dokumentów WWW i informacje o kliknięciu odnośnika oraz informacje z formularzy. Zadaniem stron WWW jest publikowanie informacji – natomiast protokół HTTP właśnie to umożliwia.
Protokół HTTP jest użyteczny, ponieważ udostępnia znormalizowany sposób komunikowania się komputerów ze sobą. Określa on formę żądań klienta (tj. np. przeglądarki www) dotyczących danych oraz formę odpowiedzi serwera na te żądania. Jest zaliczany do protokołów bezstanowych (ang. stateless) z racji tego, że nie zachowuje żadnych informacji o poprzednich transakcjach z klientem (po zakończeniu transakcji wszystko "przepada"). Pozwala to znacznie zmniejszyć obciążenie serwera, jednak jest kłopotliwe w sytuacji, gdy np. trzeba zapamiętać konkretny stan dla użytkownika, który wcześniej łączył się już z serwerem. Najczęstszym rozwiązaniem tego problemu jest wprowadzenie mechanizmu ciasteczek. Inne podejścia to m.in. sesje po stronie serwera, ukryte parametry (gdy aktualna strona zawiera formularz) oraz parametry umieszczone w URL-u (jak np. /index.php?userid=3).
HTTP standardowo korzysta z portu nr 80 (TCP).},
	language = {pl},
	urldate = {2022-05-30},
	journal = {Wikipedia, wolna encyklopedia},
	month = dec,
	year = {2021},
	note = {Page Version ID: 65497426},
}

@misc{noauthor_tim_2022,
	title = {Tim {Berners}-{Lee}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://pl.wikipedia.org/w/index.php?title=Tim_Berners-Lee&oldid=66605387},
	abstract = {Timothy Berners-Lee (ur. 8 czerwca 1955 w Londynie) – brytyjski fizyk i programista, współtwórca i jeden z pionierów usługi WWW, jednej z najpopularniejszych usług internetowych. Od 1994 jest przewodniczącym W3C.},
	language = {pl},
	urldate = {2022-05-30},
	journal = {Wikipedia, wolna encyklopedia},
	month = mar,
	year = {2022},
	note = {Page Version ID: 66605387},
}

@misc{noauthor_world_2021,
	title = {World {Wide} {Web}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://pl.wikipedia.org/w/index.php?title=World_Wide_Web&oldid=65753347},
	abstract = {World Wide Web [ˌwɜ:ldˌwaɪdˈwɛb] (sieć ogólnoświatowa, światowa rozległa sieć komputerowa), w skrócie WWW lub Web – hipertekstowy, multimedialny, internetowy system informacyjny oparty na publicznie dostępnych, otwartych standardach IETF i W3C. WWW jest usługą internetową, która ze względu na zdobytą popularność bywa błędnie utożsamiana z całym Internetem, szczególnie przez początkujących użytkowników.},
	language = {pl},
	urldate = {2022-05-30},
	journal = {Wikipedia, wolna encyklopedia},
	month = dec,
	year = {2021},
	note = {Page Version ID: 65753347},
}

@misc{noauthor_web_2022,
	title = {Web server},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Web_server&oldid=1088485457},
	abstract = {A web server is computer software and underlying hardware that accepts requests via HTTP (the network protocol created to distribute web content) or its secure variant HTTPS. A user agent, commonly a web browser or web crawler, initiates communication by making a request for a web page or other resource using HTTP, and the server responds with the content of that resource or an error message. A web server can also accept and store resources sent from the user agent if configured to do so.The hardware used to run a web server can vary according to the volume of requests that it needs to handle. At the low end of the range are embedded systems, such as a router that runs a small web server as its configuration interface. A high-traffic Internet website might handle requests with hundreds of servers that run on racks of high-speed computers.
A resource sent from a web server can be a preexisting file (static content) available to the web server, or it can be generated at the time of the request (dynamic content) by another program that communicates with the server software. The former usually can be served faster and can be more easily cached for repeated requests, while the latter supports a broader range of applications.
Technologies such as REST and SOAP, which use HTTP as a basis for general computer-to-computer communication, as well as support for WebDAV extensions, have extended the application of web servers well beyond their original purpose of serving human-readable pages.},
	language = {en},
	urldate = {2022-05-30},
	journal = {Wikipedia},
	month = may,
	year = {2022},
	note = {Page Version ID: 1088485457},
}

@misc{noauthor_model_2022,
	title = {Model {TCP}/{IP}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://pl.wikipedia.org/w/index.php?title=Model_TCP/IP&oldid=66225217},
	abstract = {Model TCP/IP (ang. Transmission Control Protocol/Internet Protocol) – teoretyczny model warstwowej struktury protokołów komunikacyjnych. Model TCP/IP został stworzony w latach 70. XX wieku w DARPA, aby pomóc w tworzeniu odpornych na atak sieci komputerowych. Potem stał się podstawą struktury Internetu.},
	language = {pl},
	urldate = {2022-05-30},
	journal = {Wikipedia, wolna encyklopedia},
	month = feb,
	year = {2022},
	note = {Page Version ID: 66225217},
}

@misc{noauthor_defense_2022,
	title = {Defense {Advanced} {Research} {Projects} {Agency}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://pl.wikipedia.org/w/index.php?title=Defense_Advanced_Research_Projects_Agency&oldid=66365360},
	abstract = {Defense Advanced Research Projects Agency – DARPA (Agencja Zaawansowanych Projektów Badawczych w Obszarze Obronności). W latach 1958-1972 i 1993-1996 pod nazwą – Advanced Research Projects Agency – ARPA (Agencja Zaawansowanych Projektów Badawczych) – amerykańska agencja rządowa zajmująca się rozwojem technologii wojskowej działająca w strukturach Departamentu Obrony.
Na zlecenie Departamentu Obrony w 1967 rozpoczęła projekt budowy zdecentralizowanej sieci komputerowej, którą nazwano później ARPANET i która zapoczątkowała rozwój Internetu. Na początku lat 70. agencja DARPA współfinansowała opracowanie zestawu protokołów TCP/IP. DARPA nigdy nie prowadziła badań samodzielnie, zajmowała się finansowaniem wyższych uczelni, instytucji komercyjnych i innych organizacji (non-profit).
W 1981 DARPA założyła grupę ekspertów – ICCB (Internet Configuration Control Board). Zadaniem grupy było zarządzanie przebiegiem prac badawczych prowadzonych w związku z siecią Internet. W 1984 agencja przekształciła ICCB w IAB (Internet Activities Board), która z kolei została podzielona na grupy robocze, zajmujące się takimi zagadnieniami jak zastosowanie, współdziałania, bezpieczeństwo i testowanie. Na koniec IAB została przekształcona w IETF (Internet Engineering Task Force) oraz w IRTF (Internet Research Task Force). Grupy te były odpowiedzialne za rozwój konstrukcji sieci Internet i badania nad rozwojami w tej dziedzinie.
Agencja rozwija w ramach Future Combat Systems wiele projektów min: egzoszkielet wspomagany, UAV różnej wielkości, i lądowe pojazdy autonomiczne UGCV.
W 2004 roku DARPA zaczęła sponsorować DARPA Grand Challenge, wyścigi zautomatyzowanych samochodów bez kierowców też w ramach FCS.
W maju 2004 r. agencja przejęła aktywa korporacji  Frontiers System Inc, produkującej bezzałogowe śmigłowce A160 Hummingbird.
DARPA prowadzi badania, rozwija technicznie i koorydynuje pod względem naukowym program globalnej obrony antybalistycznej USA.
Defense Advanced Research Projects Agency rozwija projekt budowy wielkiego działa elektromagnetycznego. Wyrzutnia ta ma wystrzeliwać wojskowe satelity na orbitę, oraz niszczyć wystrzeliwanymi elektromagnetycznie pociskami naddźwiękowe wrogie pociski.
Agencja Zaawansowanych Obronnych Projektów Badawczych Departamentu Obrony USA rozwija wojskowy-naukowy program pogodowy HAARP.
Agencja zainwestowała w badania nad aparatem wykonującym zdjęcia w wysokiej rozdzielczości.},
	language = {pl},
	urldate = {2022-05-30},
	journal = {Wikipedia, wolna encyklopedia},
	month = feb,
	year = {2022},
	note = {Page Version ID: 66365360},
}

@misc{noauthor_arpanet_2022,
	title = {{ARPANET}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://pl.wikipedia.org/w/index.php?title=ARPANET&oldid=67048312},
	abstract = {ARPANET (ang. Advanced Research Projects Agency Network) – pierwsza sieć rozległa oparta na rozproszonej architekturze i protokole TCP/IP. Jest bezpośrednim przodkiem Internetu. Został wyłączony w 1990 roku.},
	language = {pl},
	urldate = {2022-05-30},
	journal = {Wikipedia, wolna encyklopedia},
	month = apr,
	year = {2022},
	note = {Page Version ID: 67048312},
}

@misc{noauthor_hypertext_2021-1,
	title = {Hypertext {Transfer} {Protocol}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://pl.wikipedia.org/w/index.php?title=Hypertext_Transfer_Protocol&oldid=65497426},
	abstract = {HTTP (ang. Hypertext Transfer Protocol) – protokół przesyłania dokumentów hipertekstowych to protokół sieci WWW (ang. World Wide Web). Obecną definicję HTTP stanowi RFC 2616 ↓. Za pomocą protokołu HTTP przesyła się żądania udostępnienia dokumentów WWW i informacje o kliknięciu odnośnika oraz informacje z formularzy. Zadaniem stron WWW jest publikowanie informacji – natomiast protokół HTTP właśnie to umożliwia.
Protokół HTTP jest użyteczny, ponieważ udostępnia znormalizowany sposób komunikowania się komputerów ze sobą. Określa on formę żądań klienta (tj. np. przeglądarki www) dotyczących danych oraz formę odpowiedzi serwera na te żądania. Jest zaliczany do protokołów bezstanowych (ang. stateless) z racji tego, że nie zachowuje żadnych informacji o poprzednich transakcjach z klientem (po zakończeniu transakcji wszystko "przepada"). Pozwala to znacznie zmniejszyć obciążenie serwera, jednak jest kłopotliwe w sytuacji, gdy np. trzeba zapamiętać konkretny stan dla użytkownika, który wcześniej łączył się już z serwerem. Najczęstszym rozwiązaniem tego problemu jest wprowadzenie mechanizmu ciasteczek. Inne podejścia to m.in. sesje po stronie serwera, ukryte parametry (gdy aktualna strona zawiera formularz) oraz parametry umieszczone w URL-u (jak np. /index.php?userid=3).
HTTP standardowo korzysta z portu nr 80 (TCP).},
	language = {pl},
	urldate = {2022-05-30},
	journal = {Wikipedia, wolna encyklopedia},
	month = dec,
	year = {2021},
	note = {Page Version ID: 65497426},
}

@misc{noauthor_domain_2021,
	title = {Domain {Name} {System}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://pl.wikipedia.org/w/index.php?title=Domain_Name_System&oldid=64489221},
	abstract = {Domain Name System (DNS, pol. system nazw domen) – hierarchiczny rozproszony system nazw sieciowych, który odpowiada na zapytania o nazwy domen.
Dzięki DNS nazwa mnemoniczna, np. pl.wikipedia.org jest tłumaczona na odpowiadający jej adres IP, czyli 91.198.174.192. 
DNS to złożony system komputerowy oraz prawny. Zapewnia z jednej strony rejestrację nazw domen internetowych i ich powiązanie z numerami IP. Z drugiej strony realizuje bieżącą obsługę komputerów odnajdujących adresy IP odpowiadające poszczególnym nazwom. Jest nieodzowny do działania prawie wszystkich usług sieci Internet.},
	language = {pl},
	urldate = {2022-05-30},
	journal = {Wikipedia, wolna encyklopedia},
	month = sep,
	year = {2021},
	note = {Page Version ID: 64489221},
}

@misc{noauthor_welcome_nodate,
	title = {Welcome to {Flask} — {Flask} {Documentation} (2.1.x)},
	url = {https://flask.palletsprojects.com/en/2.1.x/},
	urldate = {2022-05-30},
}

@misc{noauthor_web_2022-1,
	title = {Web server},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Web_server&oldid=1088485457},
	abstract = {A web server is computer software and underlying hardware that accepts requests via HTTP (the network protocol created to distribute web content) or its secure variant HTTPS. A user agent, commonly a web browser or web crawler, initiates communication by making a request for a web page or other resource using HTTP, and the server responds with the content of that resource or an error message. A web server can also accept and store resources sent from the user agent if configured to do so.The hardware used to run a web server can vary according to the volume of requests that it needs to handle. At the low end of the range are embedded systems, such as a router that runs a small web server as its configuration interface. A high-traffic Internet website might handle requests with hundreds of servers that run on racks of high-speed computers.
A resource sent from a web server can be a preexisting file (static content) available to the web server, or it can be generated at the time of the request (dynamic content) by another program that communicates with the server software. The former usually can be served faster and can be more easily cached for repeated requests, while the latter supports a broader range of applications.
Technologies such as REST and SOAP, which use HTTP as a basis for general computer-to-computer communication, as well as support for WebDAV extensions, have extended the application of web servers well beyond their original purpose of serving human-readable pages.},
	language = {en},
	urldate = {2022-05-30},
	journal = {Wikipedia},
	month = may,
	year = {2022},
	note = {Page Version ID: 1088485457},
}

@misc{noauthor_c_nodate,
	title = {C++ {Object} {Persistence} with {ODB}},
	url = {https://www.codesynthesis.com/products/odb/doc/manual.xhtml},
	urldate = {2022-05-29},
}

@misc{chevalier_spiking_2019,
	title = {Spiking {Neural} {Network} ({SNN}) with {PyTorch}: towards bridging the gap between deep learning and the human brain},
	shorttitle = {Spiking {Neural} {Network} ({SNN}) with {PyTorch}},
	url = {https://guillaume-chevalier.com/spiking-neural-network-snn-with-pytorch-where-backpropagation-engenders-stdp-hebbian-learning/},
	abstract = {Hebbian learning naturally takes place during the backpropagation of Spiking Neural Networks (SNNs). Backpropagation in SNNs engenders STDP-like behavior.},
	language = {en-CA},
	urldate = {2022-05-25},
	journal = {Guillaume Chevalier's Blog},
	author = {Chevalier, Guillaume},
	month = jul,
	year = {2019},
	note = {Section: Time Series},
}

@misc{noauthor_introduction_nodate,
	title = {Introduction — snntorch 0.5.1 documentation},
	url = {https://snntorch.readthedocs.io/en/latest/readme.html},
	urldate = {2022-05-25},
}

@techreport{zahorodk_quantum_2021,
	title = {Quantum enhanced machine learning: {An} overview},
	shorttitle = {Quantum enhanced machine learning},
	url = {http://elibrary.kdpu.edu.ua/handle/123456789/4357},
	abstract = {Machine learning is now widely used almost everywhere, primarily for forecasting. The main idea of the work is to identify the possibility of achieving a quantum advantage when solving machine learning problems on a quantum computer.},
	language = {en},
	urldate = {2022-05-24},
	institution = {CEUR Workshop Proceedings},
	author = {Zahorodk, Pavlo V. and Modlo, Yevhenii O. and Kalinichenko, Olga O. and Selivanova, Tetiana V. and Semerikov, Serhiy O.},
	month = mar,
	year = {2021},
	doi = {10.31812/123456789/4357},
}

@misc{noauthor_support-vector_2022,
	title = {Support-vector machine},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Support-vector_machine&oldid=1079167701},
	abstract = {In machine learning, support-vector machines (SVMs, also support-vector networks) are supervised learning models with associated learning algorithms that analyze data for classification and regression analysis. Developed at AT\&T Bell Laboratories by Vladimir Vapnik with colleagues (Boser et al., 1992, Guyon et al., 1993, Cortes and Vapnik, 1995,  Vapnik et al., 1997) SVMs are one of the most robust prediction methods, being based on statistical learning frameworks or VC theory proposed by Vapnik (1982, 1995) and Chervonenkis (1974). Given a set of training examples, each marked as belonging to one of two categories, an SVM training algorithm builds a model that assigns new examples to one category or the other, making it a non-probabilistic binary linear classifier (although methods such as Platt scaling exist to use SVM in a probabilistic classification setting). SVM maps training examples to points in space so as to maximise the width of the gap between the two categories. New examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall.
In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces.
When data are unlabelled, supervised learning is not possible, and an unsupervised learning approach is required, which attempts to find natural clustering of the data to groups, and then map new data to these formed groups. The support-vector clustering algorithm, created by Hava Siegelmann and Vladimir Vapnik, applies the statistics of support vectors, developed in the support vector machines algorithm, to categorize unlabeled data.},
	language = {en},
	urldate = {2022-05-24},
	journal = {Wikipedia},
	month = mar,
	year = {2022},
	note = {Page Version ID: 1079167701},
}

@article{grabowska_applying_nodate,
	title = {Applying {Quantum} {Technology} to {Problems} in {Particle} {Physics}},
	language = {en},
	author = {Grabowska, Dorota M},
	pages = {39},
}

@misc{goodfellow_generative_2014,
	title = {Generative {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1406.2661},
	abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
	language = {en},
	urldate = {2022-05-24},
	collaborator = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	month = jun,
	year = {2014},
	note = {Number: arXiv:1406.2661
arXiv:1406.2661 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{noauthor_cern_nodate,
	title = {{CERN} {QTI} announces new seminar series {\textbar} {CERN} {QTI}},
	url = {https://quantum.cern/news/news/cern-qti-announces-new-seminar-series},
	urldate = {2022-05-24},
}

@misc{noauthor_quantum_2021,
	title = {Quantum {GAN}},
	url = {https://cds.cern.ch/record/2754278},
	abstract = {Chang, Su Yeon},
	language = {en},
	urldate = {2022-05-24},
	journal = {CERN Document Server},
	month = mar,
	year = {2021},
}

@article{abud_performance_nodate,
	title = {Performance evaluation of distributed file systems for the phase-{II} upgrade of the {ATLAS} experiment},
	language = {en},
	author = {Abud, Adam Abed and Goff, Fabrice Le and Avolio, Giuseppe},
	pages = {1},
}

@article{bernius_atlas_nodate-1,
	title = {The {ATLAS} {Trigger} \& {Data} {AcQuisition} ({TDAQ}) {System}},
	language = {en},
	author = {Bernius, Catrin},
	pages = {41},
}

@article{goff_atlas_nodate,
	title = {{ATLAS} {Solutions} for {Phase} 2 {Storage} and {Networking}},
	language = {en},
	author = {Goff, Fabrice Le},
	pages = {15},
}

@article{hoare_communicating_1978,
	title = {Communicating sequential processes},
	volume = {21},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/359576.359585},
	doi = {10.1145/359576.359585},
	abstract = {This paper suggests that input and output are basic primitives of programming and that parallel composition of communicating sequential processes is a fundamental program structuring method. When combined with a development of Dijkstra's guarded command, these concepts are surprisingly versatile. Their use is illustrated by sample solutions of a variety of familiar programming exercises.},
	language = {en},
	number = {8},
	urldate = {2022-05-23},
	journal = {Communications of the ACM},
	author = {Hoare, C. A. R.},
	month = aug,
	year = {1978},
	pages = {666--677},
}

@article{abud_rd_nodate,
	title = {R\&{D} {Studies} on a {Persistent} {Storage} {Buffer} for the {ATLAS} {Phase}-{II} {DAQ} {System}},
	language = {en},
	author = {Abud, Adam Abed and Bonaventura, Matias and Farina, Edoardo and Goff, Fabrice Le},
	pages = {1},
}

@incollection{farhadloo_fundamentals_2016,
	title = {Fundamentals of {Sentiment} {Analysis} and {Its} {Applications}},
	isbn = {9783319303178},
	abstract = {The problem of identifying people’s opinions expressed in written language is a relatively new and very active field of research. Having access to huge amount of data due to the ubiquity of Internet, has enabled researchers in different fields—such as natural language processing, machine learning and data mining
, text mining
, management and marketing and even psychology—to conduct research in order to discover people’s opinions and sentiments from the publicly available data sources. Sentiment analysis and opinion mining are typically done at various level of abstraction: document, sentence and aspect. Recently researchers are also investigating concept-level sentiment analysis
, which is a form of aspect-level sentiment analysis in which aspects can be multi terms. Also recently research has started addressing sentiment analysis and opinion mining
by using, modifying and extending topic modeling techniques. Topic models are probabilistic techniques for discovering the main themes existing in a collection of unstructured documents. In this book chapter we aim at addressing recent approaches to sentiment analysis, and explain this in the context of wider use. We start the chapter with a brief contextual introduction to the problem of sentiment analysis and opinion mining and extend our introduction with some of its applications in different domains. The main challenges in sentiment analysis and opinion mining are discussed, and different existing approaches to address these challenges are explained. Recent directions with respect to applying sentiment analysis and opinion mining
are discussed. We will review these studies towards the end of this chapter, and conclude the chapter with new opportunities for research.},
	author = {Farhadloo, Mohsen and Rolland, Erik},
	month = mar,
	year = {2016},
	doi = {10.1007/978-3-319-30319-2_1},
	pages = {1--24},
}

@inproceedings{bodyanskiy_fast_2016,
	title = {A fast learning algorithm of self-learning spiking neural network},
	doi = {10.1109/DSMP.2016.7583517},
	abstract = {The paper introduces a Newton-type modification of temporal Hebbian rule-based learning algorithm of a self-learning spiking neural network. Similar to conventional artificial neural networks domain, the learning algorithm modification based on second-order optimization procedures allows of improving performance of the third generation neural networks. The experimental research results are presented to confirm the proposed improvement of self-learning spiking neural network learning algorithm.},
	booktitle = {2016 {IEEE} {First} {International} {Conference} on {Data} {Stream} {Mining} {Processing} ({DSMP})},
	author = {Bodyanskiy, Yevgeniy and Dolotov, Artem and Pliss, Iryna and Malyar, Mykola},
	month = aug,
	year = {2016},
	keywords = {Artificial neural networks, Biological neural networks, Computational intelligence, Firing, Neurons, second order methods, self-learning spiking neural network, temporal Hebbian rule},
	pages = {104--107},
}

@article{gruning_spiking_2014,
	title = {Spiking {Neural} {Networks}: {Principles} and {Challenges}},
	shorttitle = {Spiking {Neural} {Networks}},
	url = {https://www.semanticscholar.org/paper/A-fast-learning-algorithm-of-self-learning-spiking-Bodyanskiy-Dolotov/8eb52e6d86306d21b2a5b09ab9176cf168dba34f},
	abstract = {The paper introduces a Newton-type modification of temporal Hebbian rule-based learning algorithm of a self-learning spiking neural network that allows of improving performance of the third generation neural networks. The paper introduces a Newton-type modification of temporal Hebbian rule-based learning algorithm of a self-learning spiking neural network. Similar to conventional artificial neural networks domain, the learning algorithm modification based on second-order optimization procedures allows of improving performance of the third generation neural networks. The experimental research results are presented to confirm the proposed improvement of self-learning spiking neural network learning algorithm.},
	language = {en},
	urldate = {2022-05-22},
	journal = {undefined},
	author = {Grüning, André and Bohté, S.},
	year = {2014},
}

@inproceedings{gruning_spiking_2014-1,
	title = {Spiking {Neural} {Networks}: {Principles} and {Challenges}},
	shorttitle = {Spiking {Neural} {Networks}},
	abstract = {The aim of this tutorial paper is to outline some of the common ground in state-of-the-art spiking neural networks as well as open challenges. Over the last decade, various spiking neural network models have been proposed, along with a similarly increasing interest in spiking models of computation in computational neuroscience. The aim of this tutorial paper is to outline some of the common ground in state-of-the-art spiking neural networks as well as open challenges.},
	booktitle = {{ESANN}},
	author = {Grüning, André and Bohté, S.},
	year = {2014},
}

@article{kozdon_normalisation_nodate,
	title = {Normalisation of {Weights} and {Firing} {Rates} in {Spiking} {Neural} {Networks} with {Spike}-{Timing}-{Dependent} {Plasticity}},
	abstract = {Maintaining the ability to ﬁre sparsely is crucial for information encoding in neural networks. Additionally, spiking homeostasis is vital for spiking neural networks with changing numbers of weights and neurons. We discuss a range of network stabilisation approaches, inspired by homeostatic synaptic plasticity mechanisms reported in the brain. These include weight scaling, and weight change as a function of the network’s spiking activity. We tested normalisation of the sum of weights for all neurons, and by neuron type. We examined how this approach affects ﬁring rate and performance on clustering of time-series data in the form of moving geometric shapes. We found that neuron type-speciﬁc normalisation is a promising approach for preventing weight drift in spiking neural networks, thus enabling longer training cycles. It can be adapted for networks with architectural plasticity.},
	language = {en},
	author = {Kozdon, Katarzyna and Bentley, Peter},
	pages = {4},
}

@article{wu_direct_2019,
	title = {Direct {Training} for {Spiking} {Neural} {Networks}: {Faster}, {Larger}, {Better}},
	volume = {33},
	issn = {2374-3468, 2159-5399},
	shorttitle = {Direct {Training} for {Spiking} {Neural} {Networks}},
	url = {https://aaai.org/ojs/index.php/AAAI/article/view/3929},
	doi = {10.1609/aaai.v33i01.33011311},
	abstract = {Spiking neural networks (SNNs) that enables energy efficient implementation on emerging neuromorphic hardware are gaining more attention. Yet now, SNNs have not shown competitive performance compared with artificial neural networks (ANNs), due to the lack of effective learning algorithms and efficient programming frameworks. We address this issue from two aspects: (1) We propose a neuron normalization technique to adjust the neural selectivity and develop a direct learning algorithm for deep SNNs. (2) Via narrowing the rate coding window and converting the leaky integrate-and-fire (LIF) model into an explicitly iterative version, we present a Pytorch-based implementation method towards the training of large-scale SNNs. In this way, we are able to train deep SNNs with tens of times speedup. As a result, we achieve significantly better accuracy than the reported works on neuromorphic datasets (N-MNIST and DVSCIFAR10), and comparable accuracy as existing ANNs and pre-trained SNNs on non-spiking datasets (CIFAR10). To our best knowledge, this is the first work that demonstrates direct training of deep SNNs with high performance on CIFAR10, and the efficient implementation provides a new way to explore the potential of SNNs.},
	language = {en},
	urldate = {2022-05-22},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Wu, Yujie and Deng, Lei and Li, Guoqi and Zhu, Jun and Xie, Yuan and Shi, Luping},
	month = jul,
	year = {2019},
	pages = {1311--1318},
}

@article{tavanaei_deep_2019,
	title = {Deep {Learning} in {Spiking} {Neural} {Networks}},
	volume = {111},
	issn = {08936080},
	url = {http://arxiv.org/abs/1804.08150},
	doi = {10.1016/j.neunet.2018.12.002},
	abstract = {In recent years, deep learning has been a revolution in the field of machine learning, for computer vision in particular. In this approach, a deep (multilayer) artificial neural network (ANN) is trained in a supervised manner using backpropagation. Huge amounts of labeled examples are required, but the resulting classification accuracy is truly impressive, sometimes outperforming humans. Neurons in an ANN are characterized by a single, static, continuous-valued activation. Yet biological neurons use discrete spikes to compute and transmit information, and the spike times, in addition to the spike rates, matter. Spiking neural networks (SNNs) are thus more biologically realistic than ANNs, and arguably the only viable option if one wants to understand how the brain computes. SNNs are also more hardware friendly and energy-efficient than ANNs, and are thus appealing for technology, especially for portable devices. However, training deep SNNs remains a challenge. Spiking neurons' transfer function is usually non-differentiable, which prevents using backpropagation. Here we review recent supervised and unsupervised methods to train deep SNNs, and compare them in terms of accuracy, but also computational cost and hardware friendliness. The emerging picture is that SNNs still lag behind ANNs in terms of accuracy, but the gap is decreasing, and can even vanish on some tasks, while the SNNs typically require much fewer operations.},
	urldate = {2022-05-22},
	journal = {Neural Networks},
	author = {Tavanaei, Amirhossein and Ghodrati, Masoud and Kheradpisheh, Saeed Reza and Masquelier, Timothee and Maida, Anthony S.},
	month = mar,
	year = {2019},
	note = {arXiv:1804.08150 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
	pages = {47--63},
}

@misc{noauthor_basic_2021,
	title = {Basic {Guide} to {Spiking} {Neural} {Networks} for {Deep} {Learning} {\textbar} cnvrg.io},
	url = {https://cnvrg.io/spiking-neural-networks/},
	abstract = {Nowadays, Deep Learning (DL) is a hot topic within the Data Science community. Despite being quite effective in various tasks across the industries Deep},
	language = {en-US},
	urldate = {2022-05-22},
	month = jun,
	year = {2021},
	note = {Section: Data Science},
}

@article{hu_research_2018,
	title = {Research on {Plaintext} {Restoration} of {AES} {Based} on {Neural} {Network}},
	volume = {2018},
	issn = {1939-0114},
	url = {https://www.hindawi.com/journals/scn/2018/6868506/},
	doi = {10.1155/2018/6868506},
	abstract = {Known plaintext attack is a common attack method in cryptographic attack. For ciphertext, only known part of the plaintext but unknown key, how to restore the rest of the plaintext is an important part of the known plaintext attack. This paper uses backpropagation neural networks to perform cryptanalysis on AES in an attempt to restore plaintext. The results show that the neural network can restore the entire byte with a probability of more than 40\%, restoring more than half of the plaintext bytes with a probability of more than 63\% and restoring more than half of the bytes above 89\%.},
	language = {en},
	urldate = {2022-05-22},
	journal = {Security and Communication Networks},
	author = {Hu, Xinyi and Zhao, Yaqun},
	month = nov,
	year = {2018},
	note = {Publisher: Hindawi},
	pages = {e6868506},
}

@techreport{samuels_sentiment_2020,
	title = {Sentiment {Analysis} on {Customer} {Responses}},
	url = {http://arxiv.org/abs/2007.02237},
	abstract = {Sentiment analysis is one of the fastest spreading research areas in computer science, making it challenging to keep track of all the activities in the area. We present a customer feedback reviews on product, where we utilize opinion mining, text mining and sentiments, which has affected the surrounded world by changing their opinion on a specific product. Data used in this study are online product reviews collected from Amazon.com. We performed a comparative sentiment analysis of retrieved reviews. This research paper provides you with sentimental analysis of various smart phone opinions on smart phones dividing them Positive, Negative and Neutral Behaviour.},
	number = {arXiv:2007.02237},
	urldate = {2022-05-22},
	institution = {arXiv},
	author = {Samuels, Antony and Mcgonical, John},
	month = jul,
	year = {2020},
	doi = {10.48550/arXiv.2007.02237},
	note = {arXiv:2007.02237 [cs]
type: article},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval, Computer Science - Machine Learning},
}

@inproceedings{shinto_solar_2022,
	title = {Solar {Power} {Supply} and {Environmental} {Control} {System} for {DIMS} {Experiment}},
	volume = {395},
	url = {https://pos.sissa.it/395/502/},
	doi = {10.22323/1.395.0502},
	abstract = {The DIMS experiment aims to observe a candidate of a macroscopic dark matter and interstellar meteors . Four camera modules will be installed at CLF, BRM and TARA at the TA site in Utah, USA. Since there is no power lines from the electric power company at the CLF site, we developed the power supply system using solar power generation. High sensitivity CMOS cameras are housed in four camera boxes with acrylic domes. Observation will be performed automatically every night. We also developed a system to control the temperature and humidity in the boxes by acquiring environmental data for stable observation.},
	language = {en},
	urldate = {2022-05-22},
	booktitle = {Proceedings of 37th {International} {Cosmic} {Ray} {Conference} — {PoS}({ICRC2021})},
	publisher = {SISSA Medialab},
	author = {Shinto, Daiki and Iwami, Yugo and Fujioka, Momoka and Tameda, Yuichiro and Nadamoto, Kaoru and Kajino, Fumiyoshi and Shinozaki, Kenji and on behalf of the DIMS Collaboration and Kojro, Mateusz},
	month = mar,
	year = {2022},
	pages = {502},
}

@inproceedings{barghini_characterization_2022,
	title = {Characterization of the {DIMS} system based on astronomical meteor techniques for macroscopic dark matter search},
	volume = {395},
	url = {https://pos.sissa.it/395/500/},
	doi = {10.22323/1.395.0500},
	abstract = {Nuclearites are strange quark matter conglomerates that are hypothesized as possible candidates of macroscopic dark matter. When impacting the Earth’s atmosphere, they should undergo quasi-elastic collisions with the air molecules and emit black-body radiation, thus generating atmospheric luminous events similar to meteors. However, nuclearites could be distinguished from meteors mainly by their altitude, velocity, and motion direction of the bright flight. For instance, nuclearites of galactic origins are expected to have a typical velocity of 250 km s\${\textasciicircum}\{-1\}\$, whereas meteors observed in the Earth’s atmosphere are bounded to 72 km s\${\textasciicircum}\{-1\}\$. In the case of meteoroids of interstellar origin, this value may be exceeded but, considering the stellar velocity distribution in the vicinity of the Sun, only by several kilometres per second. The DIMS (Dark matter and Interstellar Meteoroid Study) experiment was designed to search for such fast-moving particles by observing the sky with wide-field, high-sensitivity CMOS cameras. We derived the calibration of the DIMS sensors by astrometric and photometric techniques applied to observed stars in the field of view and assessed the achieved positional precision and sensitivity levels. Since nuclearites and meteor events feature quite distinct observational conditions, we optimized the DIMS setup and analysis pipeline. The distinct spectrum of mass and velocity of nuclearites must also be taken into account. We consequently evaluated the variability of nuclearites dynamics in the atmosphere in this respect. We also assessed the potentiality of the DIMS system in posing limits for macros observation based on our preliminary results. In this contribution, we will present the current status of this work.},
	language = {en},
	urldate = {2022-05-22},
	booktitle = {Proceedings of 37th {International} {Cosmic} {Ray} {Conference} — {PoS}({ICRC2021})},
	publisher = {SISSA Medialab},
	author = {Barghini, Dario and Valenti, Simone and Abe, Shinsuke and Arahori, Mizuho and Bertaina, Mario E. and Casolino, Marco and Cellino, Alberto and Covault, Corbin and Ebisuzaki, Toshikazu and Fujiwara, Yasunori and Gardiol, Daniele and Hajdukova, Maria and Ide, Ryushin and Iwami, Yugo and Kajino, Fumiyoshi and Kim, Soon-Wook and Matthews, John N. and Nadamoto, Kaoru and Park, Il H. and Piotrowski, Lech and Sagawa, Hiroyuki and Shinozaki, Kenji and Shinto, Daiki and Sidhu, Jagjit Singh and Starkman, Glenn and Tada, Sachiko and Takizawa, Yoshiyuki and Tameda, Yuichiro},
	month = mar,
	year = {2022},
	pages = {500},
}

@misc{noauthor_icrc_nodate,
	title = {{ICRC} 2021},
	url = {https://indico.desy.de/event/27991/contributions/101856/},
	abstract = {37th International Cosmic Ray Conference – The Astroparticle Conference – The ICRC Conference Series has been organised biennially since 1947 under the auspices of the International Union of Pure and Applied Physics (IUPAP) and is the largest conference on Astroparticle Physics, bringing together the different topics of the field. The main topics are Cosmic Ray Physics, Gamma-Ray Astronomy, Neutrino Astronomy \& Neutrino Physics, Dark Matter Physics and Solar and Heliospheric Physics....},
	urldate = {2022-05-22},
	journal = {DESY-Konferenzverwaltung (Indico)},
}

@inproceedings{abe_dims_2022,
	title = {{DIMS} {Experiment} for {Dark} {Matter} and {Interstellar} {Meteoroid} {Study}},
	volume = {395},
	url = {https://pos.sissa.it/395/554/},
	doi = {10.22323/1.395.0554},
	abstract = {DIMS (Dark matter and Interstellar Meteoroid Study) is a new experiment aiming to search for macroscopic dark matters and interstellar meteoroids. Nuclearites are nuggets of stable strange quark matter(SQM), neutral in charge and hypothetical super-heavy macroscopic particles (macros), and may be important components of the dark matter in our Universe. Nuclearites of galactic origins would have an expected typical velocity of about 250 km/s in galactic frame, whereas in the case of a head-on collision between interstellar meteoroids with a velocity that exceeds the escape velocity of the solar system and the Earth orbiting the Sun, the geocentric velocities will be larger than 72 km/s. We study the possibility to search for such fast-moving particles by using very high-sensitivity CMOS cameras with a wide ﬁeld of view. Based on observational data of meteor events using such stereo camera systems at some locations, we estimate the observable mass ranges for the moving nuclearites and the interstellar meteoroids. Observable ﬂux limits are also estimated for these mass ranges. We designed the DIMS experiment to search for such particles. In its ﬁrst stage, the DIMS system consists of 4 high-sensitivity CMOS camera stations with a wide ﬁeld of view. The system is going to be constructed at the Telescope Array cosmic-ray-experiment site in Utah, USA. Details of the project science, plans and present status with test results are described in this paper.},
	language = {en},
	urldate = {2022-05-22},
	booktitle = {Proceedings of 37th {International} {Cosmic} {Ray} {Conference} — {PoS}({ICRC2021})},
	publisher = {SISSA Medialab},
	author = {Abe, Shinsuke and Arahori, Mizuho and Barghini, Dario and Bertaina, Mario Edoardo and Casolino, Marco and Cellino, Alberto and Covault, Corbin and Ebisuzaki, Toshikazu and Endo, Mirai and Fujioka, Momoka and Fujiwara, Yasunori and Gardiol, Daniele and Hajdukova, Maria and Hasegawa, Mari and Ide, Ryushin and Iwami, Yugo and Kajino, Fumiyoshi and Kasztelan, Marcin and Kikuchi, Keita and Kim, Soon-Wook and Kojro, Mateusz and Matthews, John N. and Nadamoto, Kaoru and Park, Il H. and Piotrowski, Lech Wiktor and Sagawa, Hiroyuki and Shinozaki, Kenji and Shinto, Daiki and Sidhu, Jagjit Singh and Starkman, Glenn and Tada, Sachiko and Takizawa, Yoshiyuki and Tameda, Yuichiro and Valenti, Simone and Vrábel, Michal},
	month = mar,
	year = {2022},
	pages = {554},
}

@techreport{barreto_sentiment_2021,
	title = {Sentiment analysis in tweets: an assessment study from classical to modern text representation models},
	shorttitle = {Sentiment analysis in tweets},
	url = {http://arxiv.org/abs/2105.14373},
	abstract = {With the growth of social medias, such as Twitter, plenty of user-generated data emerge daily. The short texts published on Twitter -- the tweets -- have earned significant attention as a rich source of information to guide many decision-making processes. However, their inherent characteristics, such as the informal, and noisy linguistic style, remain challenging to many natural language processing (NLP) tasks, including sentiment analysis. Sentiment classification is tackled mainly by machine learning-based classifiers. The literature has adopted word representations from distinct natures to transform tweets to vector-based inputs to feed sentiment classifiers. The representations come from simple count-based methods, such as bag-of-words, to more sophisticated ones, such as BERTweet, built upon the trendy BERT architecture. Nevertheless, most studies mainly focus on evaluating those models using only a small number of datasets. Despite the progress made in recent years in language modelling, there is still a gap regarding a robust evaluation of induced embeddings applied to sentiment analysis on tweets. Furthermore, while fine-tuning the model from downstream tasks is prominent nowadays, less attention has been given to adjustments based on the specific linguistic style of the data. In this context, this study fulfils an assessment of existing language models in distinguishing the sentiment expressed in tweets by using a rich collection of 22 datasets from distinct domains and five classification algorithms. The evaluation includes static and contextualized representations. Contexts are assembled from Transformer-based autoencoder models that are also fine-tuned based on the masked language model task, using a plethora of strategies.},
	number = {arXiv:2105.14373},
	urldate = {2022-05-22},
	institution = {arXiv},
	author = {Barreto, Sérgio and Moura, Ricardo and Carvalho, Jonnathan and Paes, Aline and Plastino, Alexandre},
	month = may,
	year = {2021},
	doi = {10.48550/arXiv.2105.14373},
	note = {arXiv:2105.14373 [cs]
type: article},
	keywords = {Computer Science - Artificial Intelligence},
}
