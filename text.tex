\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage[titletoc,title]{appendix}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amsmath,amsfonts,amssymb,mathtools}
\usepackage{graphicx,float}
\usepackage{minted}
\usepackage{circuitikz}
\usemintedstyle{trac}
\title{My text title}
\author{Piotr Drabik, Mateusz Kojro}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
In this paper we present the feasibility study of using deep learning techniques to attack components of the AES cryptographic algorithm. We compare the relative performance of spiking and traditional neural networks as well as the impact of the used spike encoding and decoding functions.
\end{abstract}


\section{Introduction}
Advanced Encryption standard (AES) is one of the most widely used encryption algorithms and no 

\section{Motivation}

Deep learning has proven over the years its ability for modeling and solving problems that were thought to be nearly impossible. Given this track record and emergence of new ideas in this space problems once though to be exceptionally hard need to be examine more closely with the context of recent advancements. In this paper we will investigate the feasibility of using deep learning (namely standard neural networks and spiking neural networks) in attacks on the Rijmen's mix columns algorithm - a major component of the ubiquitous AES encryption method.

\section{Theoretical background}

\subsection{Advanced Encryption Standard}

Introduced by Joan Daemen and Vincent Rijmen in year 1998, encryption standard is a widely used, fixed block size, symmetric encryption algorithm. Adopted by U.S. AES superseded DES(Data Encryption Standard) in year 2002. 

\subsubsection{Known Attacks}
To this day AES cipher has not been broken, meaning there are no known algorithms that can decipher an encrypted message without knowledge of used key, in time shorted than needed to perform brute-force attack.
In year 2002 a theoretical attack, named the "XSL attack", was announced by Nicolas Courtois and Josef Pieprzyk, the soul existence of mathematical solutions to the algorithm behind AES, poses questions about it's security. Provided by Courtois and Pieprzyk mathematical equations used to break the algorithm require enormous amounts of computational power and time, this problem might be mitigated by usage of neural-networks.

\subsubsection{Building blocks}
AES consists of 4 main building blocks, static sized key and Information block. 

\begin{itemize}
\item Encryption Key, based on chosen block size key is sized accordingly. The size of used Key specifies number of "rounds" of encoding, for 128-bit keys it is 10 rounds of encoding, 12 for 192-bit keys, 14 for 256-bit. 
\item Information block, encoded data is spited into chunks of sizes: 128, 192 or 256 bit, those are encoded separately.  
\end{itemize}
Building blocks of AES algorithm:
\begin{itemize}
\item Byte Sub
S-Box(substitution-box) stage, used to obscure relationship betweenn key and ciphertext, thus ensuring Shannon's property of confusion.
\item Shift Row
\item Mix Column
\item Add Round Key
\end{itemize}

\subsection{Spiking neural networks}

Despite its successes in many areas across number of industries broad field of deep learning is constantly expanding and evolving. One of the results of this process is the introduction of neuron models more closely resembling those found in the human brain. One of the most popular examples of this trend are "leaky integrate and fire" neurons. They allow for an introduction of time dependent activation function and doing so are overstepping one of the big simplifications introduced by traditional deep learning models. Networks composed of this kinds of neurons are often called spiking neural networks (SNN).

\section{Methods}
\subsection{Models}


\subsection{Dataset}

In order to test and compare the introduced models <we> prepared 2 datasets consisting of randomly generated <...>

\begin{itemize}
    \item The training dataset: N encoded massages with the <some> message size
    \item Evaluation dataset composed of N messages with the same sizes as the training dataset
\end{itemize}


\section{Results}

\section{Future work}

\section{Conclusions}

\end{document}
